{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17f45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f01cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b22e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = pd.read_csv('DCOILBRENTEU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc56f99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DCOILBRENTEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>47.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>46.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-05</td>\n",
       "      <td>47.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-06</td>\n",
       "      <td>46.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>85.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>84.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>83.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>83.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>84.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1566 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE DCOILBRENTEU\n",
       "0     2015-11-02        47.91\n",
       "1     2015-11-03        48.00\n",
       "2     2015-11-04        46.96\n",
       "3     2015-11-05        47.19\n",
       "4     2015-11-06        46.09\n",
       "...          ...          ...\n",
       "1561  2021-10-26        85.11\n",
       "1562  2021-10-27        84.12\n",
       "1563  2021-10-28         83.4\n",
       "1564  2021-10-29         83.1\n",
       "1565  2021-11-01        84.51\n",
       "\n",
       "[1566 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4a8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df=oil_df[oil_df.DCOILBRENTEU != '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d1b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-1e0be226cedd>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oil_df['DCOILBRENTEU']=oil_df['DCOILBRENTEU'].astype(np.float64)\n"
     ]
    }
   ],
   "source": [
    "oil_df['DCOILBRENTEU']=oil_df['DCOILBRENTEU'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1b5940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil_df['DCOILBRENTEU'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19773e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min price of oil:  9.12\n",
      "max price of oil:  86.07\n",
      "mean price of oil:  56.65166121648138\n",
      "std of price of oil:  14.024373374502488\n"
     ]
    }
   ],
   "source": [
    "print('min price of oil: ',oil_df['DCOILBRENTEU'].min())\n",
    "print('max price of oil: ',oil_df['DCOILBRENTEU'].max())\n",
    "print('mean price of oil: ',oil_df['DCOILBRENTEU'].mean())\n",
    "print('std of price of oil: ',oil_df['DCOILBRENTEU'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71580fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_df = pd.read_csv('coin_Bitcoin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce658e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Marketcap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2013-04-29 23:59:59</td>\n",
       "      <td>147.488007</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.444000</td>\n",
       "      <td>144.539993</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.603769e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2013-04-30 23:59:59</td>\n",
       "      <td>146.929993</td>\n",
       "      <td>134.050003</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.542813e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2013-05-01 23:59:59</td>\n",
       "      <td>139.889999</td>\n",
       "      <td>107.720001</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>116.989998</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.298955e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2013-05-02 23:59:59</td>\n",
       "      <td>125.599998</td>\n",
       "      <td>92.281898</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>105.209999</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.168517e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2013-05-03 23:59:59</td>\n",
       "      <td>108.127998</td>\n",
       "      <td>79.099998</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>97.750000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.085995e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>2987</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2021-07-02 23:59:59</td>\n",
       "      <td>33939.588699</td>\n",
       "      <td>32770.680780</td>\n",
       "      <td>33549.600177</td>\n",
       "      <td>33897.048590</td>\n",
       "      <td>3.872897e+10</td>\n",
       "      <td>6.354508e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>2988</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2021-07-03 23:59:59</td>\n",
       "      <td>34909.259899</td>\n",
       "      <td>33402.696536</td>\n",
       "      <td>33854.421362</td>\n",
       "      <td>34668.548402</td>\n",
       "      <td>2.438396e+10</td>\n",
       "      <td>6.499397e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>2989</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2021-07-04 23:59:59</td>\n",
       "      <td>35937.567147</td>\n",
       "      <td>34396.477458</td>\n",
       "      <td>34665.564866</td>\n",
       "      <td>35287.779766</td>\n",
       "      <td>2.492431e+10</td>\n",
       "      <td>6.615748e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>2990</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2021-07-05 23:59:59</td>\n",
       "      <td>35284.344430</td>\n",
       "      <td>33213.661034</td>\n",
       "      <td>35284.344430</td>\n",
       "      <td>33746.002456</td>\n",
       "      <td>2.672155e+10</td>\n",
       "      <td>6.326962e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>2991</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2021-07-06 23:59:59</td>\n",
       "      <td>35038.536363</td>\n",
       "      <td>33599.916169</td>\n",
       "      <td>33723.509655</td>\n",
       "      <td>34235.193451</td>\n",
       "      <td>2.650126e+10</td>\n",
       "      <td>6.418992e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SNo     Name Symbol                 Date          High           Low  \\\n",
       "0        1  Bitcoin    BTC  2013-04-29 23:59:59    147.488007    134.000000   \n",
       "1        2  Bitcoin    BTC  2013-04-30 23:59:59    146.929993    134.050003   \n",
       "2        3  Bitcoin    BTC  2013-05-01 23:59:59    139.889999    107.720001   \n",
       "3        4  Bitcoin    BTC  2013-05-02 23:59:59    125.599998     92.281898   \n",
       "4        5  Bitcoin    BTC  2013-05-03 23:59:59    108.127998     79.099998   \n",
       "...    ...      ...    ...                  ...           ...           ...   \n",
       "2986  2987  Bitcoin    BTC  2021-07-02 23:59:59  33939.588699  32770.680780   \n",
       "2987  2988  Bitcoin    BTC  2021-07-03 23:59:59  34909.259899  33402.696536   \n",
       "2988  2989  Bitcoin    BTC  2021-07-04 23:59:59  35937.567147  34396.477458   \n",
       "2989  2990  Bitcoin    BTC  2021-07-05 23:59:59  35284.344430  33213.661034   \n",
       "2990  2991  Bitcoin    BTC  2021-07-06 23:59:59  35038.536363  33599.916169   \n",
       "\n",
       "              Open         Close        Volume     Marketcap  \n",
       "0       134.444000    144.539993  0.000000e+00  1.603769e+09  \n",
       "1       144.000000    139.000000  0.000000e+00  1.542813e+09  \n",
       "2       139.000000    116.989998  0.000000e+00  1.298955e+09  \n",
       "3       116.379997    105.209999  0.000000e+00  1.168517e+09  \n",
       "4       106.250000     97.750000  0.000000e+00  1.085995e+09  \n",
       "...            ...           ...           ...           ...  \n",
       "2986  33549.600177  33897.048590  3.872897e+10  6.354508e+11  \n",
       "2987  33854.421362  34668.548402  2.438396e+10  6.499397e+11  \n",
       "2988  34665.564866  35287.779766  2.492431e+10  6.615748e+11  \n",
       "2989  35284.344430  33746.002456  2.672155e+10  6.326962e+11  \n",
       "2990  33723.509655  34235.193451  2.650126e+10  6.418992e+11  \n",
       "\n",
       "[2991 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b07a7c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_df['Close'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0beee379",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_edit = coin_df['Date'].values.tolist()\n",
    "for i in range(len(date_edit)):\n",
    "    date_edit[i] = date_edit[i][0:10]\n",
    "coin_df['Date'] = date_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d348fea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2013-04-29\n",
       "1       2013-04-30\n",
       "2       2013-05-01\n",
       "3       2013-05-02\n",
       "4       2013-05-03\n",
       "           ...    \n",
       "2986    2021-07-02\n",
       "2987    2021-07-03\n",
       "2988    2021-07-04\n",
       "2989    2021-07-05\n",
       "2990    2021-07-06\n",
       "Name: Date, Length: 2991, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c50917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-29</td>\n",
       "      <td>144.539993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>116.989998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>105.209999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>97.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>33897.048590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>34668.548402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>35287.779766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>33746.002456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>34235.193451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Close\n",
       "0     2013-04-29    144.539993\n",
       "1     2013-04-30    139.000000\n",
       "2     2013-05-01    116.989998\n",
       "3     2013-05-02    105.209999\n",
       "4     2013-05-03     97.750000\n",
       "...          ...           ...\n",
       "2986  2021-07-02  33897.048590\n",
       "2987  2021-07-03  34668.548402\n",
       "2988  2021-07-04  35287.779766\n",
       "2989  2021-07-05  33746.002456\n",
       "2990  2021-07-06  34235.193451\n",
       "\n",
       "[2991 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coin_df = coin_df[['Date','Close']]\n",
    "new_coin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d405cf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         144.539993\n",
       "1         139.000000\n",
       "2         116.989998\n",
       "3         105.209999\n",
       "4          97.750000\n",
       "            ...     \n",
       "2986    33897.048590\n",
       "2987    34668.548402\n",
       "2988    35287.779766\n",
       "2989    33746.002456\n",
       "2990    34235.193451\n",
       "Name: Close, Length: 2991, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coin_df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26f819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min price of Bitcoin:  68.43099975585938\n",
      "max price of Bitcoin:  63503.45793019\n",
      "mean price of Bitcoin:  6711.290443071496\n",
      "std of price of Bitcoin:  11298.14192140347\n"
     ]
    }
   ],
   "source": [
    "print('min price of Bitcoin: ',new_coin_df['Close'].min())\n",
    "print('max price of Bitcoin: ',new_coin_df['Close'].max())\n",
    "print('mean price of Bitcoin: ',new_coin_df['Close'].mean())\n",
    "print('std of price of Bitcoin: ',new_coin_df['Close'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58eca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4cd638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_train_test (batch_size,data,percent,num_predicts):\n",
    "    length_train = int(data.shape[0]*(1-percent))\n",
    "    a1 = length_train//batch_size\n",
    "    length_train = batch_size*a1\n",
    "    train_data = data.iloc[:,1:2].values\n",
    "    train_data = scaler.fit_transform(train_data)\n",
    "    train_set = []\n",
    "    train_label = []\n",
    "    for i in range(length_train):\n",
    "        train_set.append(train_data[i:i + num_predicts])\n",
    "        train_label.append(train_data[i + num_predicts:i + 2*num_predicts])\n",
    "    \n",
    "    length_test = int(data.shape[0] - length_train - 4*num_predicts)\n",
    "    a2 = length_test//batch_size\n",
    "    length_test = int(batch_size*a2) \n",
    "    test = data.iloc[:,1:2].values\n",
    "    test = scaler.fit_transform(test)\n",
    "    test_data = test[length_train + 2*num_predicts:length_train + length_test + 4*num_predicts]\n",
    "    test_set = []\n",
    "    test_label = []\n",
    "    for j in range(length_test):\n",
    "        test_set.append(test_data[j:j + num_predicts])\n",
    "        test_label.append(test_data[j + num_predicts:j + 2*num_predicts])\n",
    "        \n",
    "    \n",
    "    train_set = np.reshape(np.array(train_set),(np.array(train_set).shape[0], np.array(train_set).shape[1], 1))\n",
    "    train_label = np.reshape(np.array(train_label),(np.array(train_label).shape[0], np.array(train_label).shape[1]))\n",
    "    test_set = np.reshape(np.array(test_set),(np.array(test_set).shape[0], np.array(test_set).shape[1], 1))\n",
    "    test_label = np.reshape(np.array(test_label),(np.array(test_label).shape[0], np.array(test_label).shape[1]))\n",
    "    \n",
    "    return train_set, train_label, test_set, test_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "234bacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_label, test_set, test_label = format_train_test(64,new_coin_df,0.2,5)\n",
    "\n",
    "train_set, train_label, test_set, test_label = map(torch.tensor,(train_set, train_label, test_set, test_label))\n",
    "\n",
    "train = TensorDataset(train_set, train_label)\n",
    "train_tensor = DataLoader(train, batch_size = 64, shuffle=False)\n",
    "\n",
    "test = TensorDataset(test_set, test_label)\n",
    "test_tensor = DataLoader(test, batch_size= 64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1577e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, out_size, in_size, hidden_size1, hidden_size2,batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.lstm1 = nn.LSTM(input_size=self.in_size,hidden_size=self.hidden_size1,num_layers=2,batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.hidden_size1,hidden_size=self.hidden_size2,num_layers=2,batch_first=True)\n",
    "        self.last = nn.Linear(self.hidden_size2, self.out_size)\n",
    "    def forward(self,x,old_state):\n",
    "        s1,state1 = self.lstm1(x,old_state)\n",
    "        s2,state2 = self.lstm2(s1,state1)\n",
    "        return self.last(s2), state2\n",
    "    def initial_s(self, num_predicts):\n",
    "        return (torch.zeros(2,self.batch_size, self.hidden_size1),\n",
    "                torch.zeros(2,self.batch_size, self.hidden_size1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b6f52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb85dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_model(5,1,5,5,64)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0592041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_model(\n",
      "  (lstm1): LSTM(1, 5, num_layers=2, batch_first=True)\n",
      "  (lstm2): LSTM(5, 5, num_layers=2, batch_first=True)\n",
      "  (last): Linear(in_features=5, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1450495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model,train_tensor,test_tensor,criterion,optimizer,device,num_predicts,iterations):\n",
    "    for i in range(iterations):\n",
    "        h0, c0 = model.initial_s(num_predicts)\n",
    "        h, c = h0.to(device), c0.to(device)\n",
    "        for (x,y) in train_tensor:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat, (h, c) = model(x.float(), (h, c))\n",
    "            loss = criterion(y_hat, y.long())\n",
    "            h = h.detach()\n",
    "            c = c.detach()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            h01, c01 = model.initial_s(num_predicts)\n",
    "            h1, c1 = h01.to(device), c01.to(device)\n",
    "            lost_val = 0\n",
    "            for (x1, y1) in test_tensor:\n",
    "                x1, y1 = x1.to(device), y1.to(device)\n",
    "                y_hat1, (h1, c1) = model(x1.float(),(h1,c1))\n",
    "                loss1 = criterion(y_hat1, y1.long())\n",
    "                lost_val += loss1.item()\n",
    "                h1 = h1.detach()\n",
    "                c1 = c1.detach()\n",
    "            lost_val /= len(x1)\n",
    "            print(f\"Iteration {i+1}\\n********************\")\n",
    "            print('The loss for train is: ',loss.item())\n",
    "            print('The loss for test is: ',lost_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d72567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "********************\n",
      "The loss for train is:  1.580761194229126\n",
      "The loss for test is:  0.2221520785242319\n",
      "Iteration 2\n",
      "********************\n",
      "The loss for train is:  1.4932750463485718\n",
      "The loss for test is:  0.20948922634124756\n",
      "Iteration 3\n",
      "********************\n",
      "The loss for train is:  1.2867605686187744\n",
      "The loss for test is:  0.17983133345842361\n",
      "Iteration 4\n",
      "********************\n",
      "The loss for train is:  0.9603341221809387\n",
      "The loss for test is:  0.1338758636265993\n",
      "Iteration 5\n",
      "********************\n",
      "The loss for train is:  0.6447484493255615\n",
      "The loss for test is:  0.09011944849044085\n",
      "Iteration 6\n",
      "********************\n",
      "The loss for train is:  0.42319363355636597\n",
      "The loss for test is:  0.05946787493303418\n",
      "Iteration 7\n",
      "********************\n",
      "The loss for train is:  0.2900962829589844\n",
      "The loss for test is:  0.04107495490461588\n",
      "Iteration 8\n",
      "********************\n",
      "The loss for train is:  0.2100238800048828\n",
      "The loss for test is:  0.03001663344912231\n",
      "Iteration 9\n",
      "********************\n",
      "The loss for train is:  0.15913185477256775\n",
      "The loss for test is:  0.022973094368353486\n",
      "Iteration 10\n",
      "********************\n",
      "The loss for train is:  0.12470443546772003\n",
      "The loss for test is:  0.018224188592284918\n",
      "Iteration 11\n",
      "********************\n",
      "The loss for train is:  0.1003914326429367\n",
      "The loss for test is:  0.014862543670460582\n",
      "Iteration 12\n",
      "********************\n",
      "The loss for train is:  0.08250055462121964\n",
      "The loss for test is:  0.012393398792482913\n",
      "Iteration 13\n",
      "********************\n",
      "The loss for train is:  0.06892162561416626\n",
      "The loss for test is:  0.010519598610699177\n",
      "Iteration 14\n",
      "********************\n",
      "The loss for train is:  0.05833929777145386\n",
      "The loss for test is:  0.009069892461411655\n",
      "Iteration 15\n",
      "********************\n",
      "The loss for train is:  0.04999297112226486\n",
      "The loss for test is:  0.007929713348858058\n",
      "Iteration 16\n",
      "********************\n",
      "The loss for train is:  0.043275509029626846\n",
      "The loss for test is:  0.007020935590844601\n",
      "Iteration 17\n",
      "********************\n",
      "The loss for train is:  0.0378446951508522\n",
      "The loss for test is:  0.006289021926932037\n",
      "Iteration 18\n",
      "********************\n",
      "The loss for train is:  0.03338613733649254\n",
      "The loss for test is:  0.005694922409020364\n",
      "Iteration 19\n",
      "********************\n",
      "The loss for train is:  0.029710527509450912\n",
      "The loss for test is:  0.005204465560382232\n",
      "Iteration 20\n",
      "********************\n",
      "The loss for train is:  0.026628974825143814\n",
      "The loss for test is:  0.004799044312676415\n",
      "Iteration 21\n",
      "********************\n",
      "The loss for train is:  0.024007119238376617\n",
      "The loss for test is:  0.004459626943571493\n",
      "Iteration 22\n",
      "********************\n",
      "The loss for train is:  0.021793948486447334\n",
      "The loss for test is:  0.004173391906078905\n",
      "Iteration 23\n",
      "********************\n",
      "The loss for train is:  0.019876960664987564\n",
      "The loss for test is:  0.003928293532226235\n",
      "Iteration 24\n",
      "********************\n",
      "The loss for train is:  0.018228158354759216\n",
      "The loss for test is:  0.0037190945586189628\n",
      "Iteration 25\n",
      "********************\n",
      "The loss for train is:  0.016788603737950325\n",
      "The loss for test is:  0.00353782219463028\n",
      "Iteration 26\n",
      "********************\n",
      "The loss for train is:  0.015521044842898846\n",
      "The loss for test is:  0.0033789857116062194\n",
      "Iteration 27\n",
      "********************\n",
      "The loss for train is:  0.014389976859092712\n",
      "The loss for test is:  0.003240113423089497\n",
      "Iteration 28\n",
      "********************\n",
      "The loss for train is:  0.013393355533480644\n",
      "The loss for test is:  0.003118456690572202\n",
      "Iteration 29\n",
      "********************\n",
      "The loss for train is:  0.01250720489770174\n",
      "The loss for test is:  0.0030104548059171066\n",
      "Iteration 30\n",
      "********************\n",
      "The loss for train is:  0.011706091463565826\n",
      "The loss for test is:  0.002915186414611526\n",
      "Iteration 31\n",
      "********************\n",
      "The loss for train is:  0.01097951177507639\n",
      "The loss for test is:  0.002828891185345128\n",
      "Iteration 32\n",
      "********************\n",
      "The loss for train is:  0.010323653928935528\n",
      "The loss for test is:  0.0027519798459252343\n",
      "Iteration 33\n",
      "********************\n",
      "The loss for train is:  0.009727117605507374\n",
      "The loss for test is:  0.002683215032448061\n",
      "Iteration 34\n",
      "********************\n",
      "The loss for train is:  0.009185628965497017\n",
      "The loss for test is:  0.0026211017975583673\n",
      "Iteration 35\n",
      "********************\n",
      "The loss for train is:  0.008689537644386292\n",
      "The loss for test is:  0.0025647445436334237\n",
      "Iteration 36\n",
      "********************\n",
      "The loss for train is:  0.008234431967139244\n",
      "The loss for test is:  0.0025148260610876605\n",
      "Iteration 37\n",
      "********************\n",
      "The loss for train is:  0.0078047094866633415\n",
      "The loss for test is:  0.002468050668539945\n",
      "Iteration 38\n",
      "********************\n",
      "The loss for train is:  0.007422448601573706\n",
      "The loss for test is:  0.0024262496081064455\n",
      "Iteration 39\n",
      "********************\n",
      "The loss for train is:  0.007063031196594238\n",
      "The loss for test is:  0.0023872482270235196\n",
      "Iteration 40\n",
      "********************\n",
      "The loss for train is:  0.006731911096721888\n",
      "The loss for test is:  0.002352181480091531\n",
      "Iteration 41\n",
      "********************\n",
      "The loss for train is:  0.006420210003852844\n",
      "The loss for test is:  0.002320480823982507\n",
      "Iteration 42\n",
      "********************\n",
      "The loss for train is:  0.006129265297204256\n",
      "The loss for test is:  0.0022909128965693526\n",
      "Iteration 43\n",
      "********************\n",
      "The loss for train is:  0.005863002967089415\n",
      "The loss for test is:  0.0022641474206466228\n",
      "Iteration 44\n",
      "********************\n",
      "The loss for train is:  0.005609758198261261\n",
      "The loss for test is:  0.0022395145060727373\n",
      "Iteration 45\n",
      "********************\n",
      "The loss for train is:  0.005376017186790705\n",
      "The loss for test is:  0.002216581633547321\n",
      "Iteration 46\n",
      "********************\n",
      "The loss for train is:  0.005156008061021566\n",
      "The loss for test is:  0.0021953165414743125\n",
      "Iteration 47\n",
      "********************\n",
      "The loss for train is:  0.004951958078891039\n",
      "The loss for test is:  0.002176486043026671\n",
      "Iteration 48\n",
      "********************\n",
      "The loss for train is:  0.004751029424369335\n",
      "The loss for test is:  0.002158526171115227\n",
      "Iteration 49\n",
      "********************\n",
      "The loss for train is:  0.00456933444365859\n",
      "The loss for test is:  0.002142503311915789\n",
      "Iteration 50\n",
      "********************\n",
      "The loss for train is:  0.004389014560729265\n",
      "The loss for test is:  0.0021269322678563185\n",
      "Iteration 51\n",
      "********************\n",
      "The loss for train is:  0.004232350736856461\n",
      "The loss for test is:  0.002113178270519711\n",
      "Iteration 52\n",
      "********************\n",
      "The loss for train is:  0.0040725586004555225\n",
      "The loss for test is:  0.0021000559790991247\n",
      "Iteration 53\n",
      "********************\n",
      "The loss for train is:  0.003926803357899189\n",
      "The loss for test is:  0.0020887112041236833\n",
      "Iteration 54\n",
      "********************\n",
      "The loss for train is:  0.0037876316346228123\n",
      "The loss for test is:  0.0020771616109414026\n",
      "Iteration 55\n",
      "********************\n",
      "The loss for train is:  0.003655108157545328\n",
      "The loss for test is:  0.002067314457235625\n",
      "Iteration 56\n",
      "********************\n",
      "The loss for train is:  0.0035305351484566927\n",
      "The loss for test is:  0.002058082878647838\n",
      "Iteration 57\n",
      "********************\n",
      "The loss for train is:  0.003411443205550313\n",
      "The loss for test is:  0.002049568687652936\n",
      "Iteration 58\n",
      "********************\n",
      "The loss for train is:  0.00329807517118752\n",
      "The loss for test is:  0.002041747109615244\n",
      "Iteration 59\n",
      "********************\n",
      "The loss for train is:  0.0031877816654741764\n",
      "The loss for test is:  0.0020344807671790477\n",
      "Iteration 60\n",
      "********************\n",
      "The loss for train is:  0.003084595315158367\n",
      "The loss for test is:  0.002027441376412753\n",
      "Iteration 61\n",
      "********************\n",
      "The loss for train is:  0.0029857070185244083\n",
      "The loss for test is:  0.0020215327858750243\n",
      "Iteration 62\n",
      "********************\n",
      "The loss for train is:  0.002889314666390419\n",
      "The loss for test is:  0.0020158092411293183\n",
      "Iteration 63\n",
      "********************\n",
      "The loss for train is:  0.002802362432703376\n",
      "The loss for test is:  0.0020108515200263355\n",
      "Iteration 64\n",
      "********************\n",
      "The loss for train is:  0.0027190663386136293\n",
      "The loss for test is:  0.0020060727765667252\n",
      "Iteration 65\n",
      "********************\n",
      "The loss for train is:  0.002633498515933752\n",
      "The loss for test is:  0.0020018143331981264\n",
      "Iteration 66\n",
      "********************\n",
      "The loss for train is:  0.00255408463999629\n",
      "The loss for test is:  0.0019977210940851364\n",
      "Iteration 67\n",
      "********************\n",
      "The loss for train is:  0.002477408852428198\n",
      "The loss for test is:  0.0019944413543271367\n",
      "Iteration 68\n",
      "********************\n",
      "The loss for train is:  0.0024047880433499813\n",
      "The loss for test is:  0.0019911754861823283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 69\n",
      "********************\n",
      "The loss for train is:  0.0023341327905654907\n",
      "The loss for test is:  0.0019883093518728856\n",
      "Iteration 70\n",
      "********************\n",
      "The loss for train is:  0.0022670684847980738\n",
      "The loss for test is:  0.001985856240935391\n",
      "Iteration 71\n",
      "********************\n",
      "The loss for train is:  0.002202586503699422\n",
      "The loss for test is:  0.0019836069222947117\n",
      "Iteration 72\n",
      "********************\n",
      "The loss for train is:  0.0021408218890428543\n",
      "The loss for test is:  0.0019816879103018437\n",
      "Iteration 73\n",
      "********************\n",
      "The loss for train is:  0.0020813082810491323\n",
      "The loss for test is:  0.0019798761459242087\n",
      "Iteration 74\n",
      "********************\n",
      "The loss for train is:  0.0020231143571436405\n",
      "The loss for test is:  0.0019785747717833146\n",
      "Iteration 75\n",
      "********************\n",
      "The loss for train is:  0.0019691598135977983\n",
      "The loss for test is:  0.001977394291316159\n",
      "Iteration 76\n",
      "********************\n",
      "The loss for train is:  0.0019148109713569283\n",
      "The loss for test is:  0.001976249657673179\n",
      "Iteration 77\n",
      "********************\n",
      "The loss for train is:  0.0018642202485352755\n",
      "The loss for test is:  0.0019754176901187748\n",
      "Iteration 78\n",
      "********************\n",
      "The loss for train is:  0.0018138119485229254\n",
      "The loss for test is:  0.001974949342184118\n",
      "Iteration 79\n",
      "********************\n",
      "The loss for train is:  0.0017658050637692213\n",
      "The loss for test is:  0.0019747236037801486\n",
      "Iteration 80\n",
      "********************\n",
      "The loss for train is:  0.001719157793559134\n",
      "The loss for test is:  0.00197435678455804\n",
      "Iteration 81\n",
      "********************\n",
      "The loss for train is:  0.0016750568756833673\n",
      "The loss for test is:  0.0019743481589102885\n",
      "Iteration 82\n",
      "********************\n",
      "The loss for train is:  0.0016332289669662714\n",
      "The loss for test is:  0.001974478027477744\n",
      "Iteration 83\n",
      "********************\n",
      "The loss for train is:  0.0015891302609816194\n",
      "The loss for test is:  0.001974544598851935\n",
      "Iteration 84\n",
      "********************\n",
      "The loss for train is:  0.0015498690772801638\n",
      "The loss for test is:  0.0019750249848584644\n",
      "Iteration 85\n",
      "********************\n",
      "The loss for train is:  0.0015100184828042984\n",
      "The loss for test is:  0.0019756355959543725\n",
      "Iteration 86\n",
      "********************\n",
      "The loss for train is:  0.0014738013269379735\n",
      "The loss for test is:  0.001976404566448764\n",
      "Iteration 87\n",
      "********************\n",
      "The loss for train is:  0.001435494632460177\n",
      "The loss for test is:  0.001977098057977855\n",
      "Iteration 88\n",
      "********************\n",
      "The loss for train is:  0.0014002446550875902\n",
      "The loss for test is:  0.001977934909518808\n",
      "Iteration 89\n",
      "********************\n",
      "The loss for train is:  0.0013662579003721476\n",
      "The loss for test is:  0.0019791730683209607\n",
      "Iteration 90\n",
      "********************\n",
      "The loss for train is:  0.0013327274937182665\n",
      "The loss for test is:  0.0019801838552666595\n",
      "Iteration 91\n",
      "********************\n",
      "The loss for train is:  0.0013004614738747478\n",
      "The loss for test is:  0.001981392038942431\n",
      "Iteration 92\n",
      "********************\n",
      "The loss for train is:  0.0012699586804956198\n",
      "The loss for test is:  0.001982849837077083\n",
      "Iteration 93\n",
      "********************\n",
      "The loss for train is:  0.0012379251420497894\n",
      "The loss for test is:  0.001984323100259644\n",
      "Iteration 94\n",
      "********************\n",
      "The loss for train is:  0.001209090230986476\n",
      "The loss for test is:  0.0019857223760482157\n",
      "Iteration 95\n",
      "********************\n",
      "The loss for train is:  0.0011810909491032362\n",
      "The loss for test is:  0.0019871734257321805\n",
      "Iteration 96\n",
      "********************\n",
      "The loss for train is:  0.0011530265910550952\n",
      "The loss for test is:  0.0019890776893589646\n",
      "Iteration 97\n",
      "********************\n",
      "The loss for train is:  0.0011261493200436234\n",
      "The loss for test is:  0.001991048422496533\n",
      "Iteration 98\n",
      "********************\n",
      "The loss for train is:  0.0010993056930601597\n",
      "The loss for test is:  0.0019928078072553035\n",
      "Iteration 99\n",
      "********************\n",
      "The loss for train is:  0.0010740214493125677\n",
      "The loss for test is:  0.0019945840249420144\n",
      "Iteration 100\n",
      "********************\n",
      "The loss for train is:  0.0010493205627426505\n",
      "The loss for test is:  0.0019968878223153297\n"
     ]
    }
   ],
   "source": [
    "train_test(model,train_tensor,test_tensor,criterion,optimizer,device,5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229bb97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
