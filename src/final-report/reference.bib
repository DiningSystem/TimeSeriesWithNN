@article{PURUSHOTHAM2018112,
title = {Benchmarking deep learning models on large healthcare datasets},
journal = {Journal of Biomedical Informatics},
volume = {83},
pages = {112-134},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2018.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S1532046418300716},
author = {Sanjay Purushotham and Chuizheng Meng and Zhengping Che and Yan Liu},
keywords = {Deep learning models, Super learner algorithm, Mortality prediction, Length of stay, ICD-9 code group prediction},
abstract = {Deep learning models (aka Deep Neural Networks) have revolutionized many fields including computer vision, natural language processing, speech recognition, and is being increasingly used in clinical healthcare applications. However, few works exist which have benchmarked the performance of the deep learning models with respect to the state-of-the-art machine learning models and prognostic scoring systems on publicly available healthcare datasets. In this paper, we present the benchmarking results for several clinical prediction tasks such as mortality prediction, length of stay prediction, and ICD-9 code group prediction using Deep Learning models, ensemble of machine learning models (Super Learner algorithm), SAPS II and SOFA scores. We used the Medical Information Mart for Intensive Care III (MIMIC-III) (v1.4) publicly available dataset, which includes all patients admitted to an ICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the benchmarking tasks. Our results show that deep learning models consistently outperform all the other approaches especially when the ‘raw’ clinical time series data is used as input features to the models.}
}